{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningHW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB-ALpvOXPIF"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "y2_pred=[]\n",
        "\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x = (i-25.5)/10\n",
        "  y2 = np.cos(x)\n",
        "  y3 = np.sign(x)\n",
        "  y4 = np.floor(x)\n",
        "  labelledData['i'] = i\n",
        "  labelledData['a'] = a\n",
        "  labelledData['x'] = x\n",
        "  labelledData['y2'] = y2\n",
        "  labelledData['y3'] = y3\n",
        "  labelledData['y4'] = y4\n",
        "  labelledDataList.append(labelledData)\n",
        "\n",
        "keys = labelledDataList[0].keys()\n",
        "\n",
        "\n",
        "with open('hw3_dataset.csv', 'w') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(labelledDataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eNsttmeFtQ3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FFSN:\n",
        "  \n",
        "  def __init__(self, n_inputs, n_outputs,a, hidden_sizes=[100,100,100,100,100]):\n",
        "    self.nx = n_inputs\n",
        "    self.ny = n_outputs\n",
        "    self.nh = len(hidden_sizes)\n",
        "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
        "  \n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.nh+1):\n",
        "      self.W[i+1] = np.random.uniform(-a,a,(self.sizes[i], self.sizes[i+1]))\n",
        "      self.B[i+1] = np.full((1, self.sizes[i+1]),0.1)\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  def grad_sigmoid(self, x):\n",
        "    return x*(1-x) \n",
        "  \n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def relu(self,x):\n",
        "    return np.maximum(0,x)\n",
        "  def SE(self,yHat,y):\n",
        "    return np.square(np.subtract(yHat,y))\n",
        " \n",
        "  def grad(self, x):\n",
        "    y = self.forward_pass(x)\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dH = {}\n",
        "    self.dA = {}\n",
        "    L = self.nh +1\n",
        "    self.dA[L] = y\n",
        "    for k in range(L, 0, -1):\n",
        "      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n",
        "      self.dB[k] = self.dA[k]\n",
        "      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n",
        "      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1]))\n",
        "  \n",
        "    return y, self.dA[L]\n",
        "  def forward_pass(self, x):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = x.reshape(1, -1)\n",
        "   \n",
        "    for i in range(self.nh):\n",
        "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
        "      self.H[i+1] = self.relu(self.A[i+1])\n",
        "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
        "    self.H[self.nh+1] = self.relu(self.A[self.nh+1]) \n",
        "    return self.H[self.nh+1]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred).squeeze()\n",
        " \n",
        "  \n",
        " \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KINhQSTbuM9X",
        "outputId": "8ec41f41-64f5-4cbf-9d23-c5c17cd8d3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#a= 0.1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a=0.1\n",
        "model = FFSN(1,1,0.1,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for x in range(-5,5):\n",
        "    y,dy = model.grad(np.array(x))\n",
        "    print(\"Output y\",y)\n",
        "    print(\"Derivative of y\",dy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output y [[0.19053823]]\n",
            "Derivative of y [[0.19053823]]\n",
            "Output y [[0.18928207]]\n",
            "Derivative of y [[0.18928207]]\n",
            "Output y [[0.1885547]]\n",
            "Derivative of y [[0.1885547]]\n",
            "Output y [[0.18780421]]\n",
            "Derivative of y [[0.18780421]]\n",
            "Output y [[0.18512302]]\n",
            "Derivative of y [[0.18512302]]\n",
            "Output y [[0.18073842]]\n",
            "Derivative of y [[0.18073842]]\n",
            "Output y [[0.17758671]]\n",
            "Derivative of y [[0.17758671]]\n",
            "Output y [[0.17693534]]\n",
            "Derivative of y [[0.17693534]]\n",
            "Output y [[0.17715213]]\n",
            "Derivative of y [[0.17715213]]\n",
            "Output y [[0.17658095]]\n",
            "Derivative of y [[0.17658095]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qBjPxLWubFn",
        "outputId": "dd388bbf-6082-4bf9-ff6e-393265f954ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#a= 0.2\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a=0.2\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  Y.append(np.cos(x))\n",
        "Ypred = model.predict(np.array(X))\n",
        "error = model.SE(Ypred,Y)\n",
        "print(Ypred)\n",
        "for err in error:\n",
        "  err+=err\n",
        "MSE = err/50\n",
        "print(MSE)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw22_a02.csv\", table, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.53229881 0.52791334 0.52311823 0.51823481 0.51345252 0.50886823\n",
            " 0.50364602 0.49898627 0.49524358 0.49109703 0.48607481 0.48124635\n",
            " 0.47705144 0.47274661 0.46845924 0.46543663 0.4612474  0.45453688\n",
            " 0.45010543 0.45337365 0.45925381 0.46274484 0.46736928 0.47497709\n",
            " 0.48775909 0.50434546 0.52231789 0.53122023 0.54287593 0.55483023\n",
            " 0.56878515 0.58185076 0.59172094 0.59899305 0.60467024 0.6076611\n",
            " 0.60893557 0.60961131 0.61197418 0.61552562 0.61927814 0.6234481\n",
            " 0.62874815 0.63479154 0.64050628 0.64594223 0.65132401 0.65670579\n",
            " 0.66198038 0.66727165]\n",
            "0.08265658440516754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYILVAs4Q7UH",
        "outputId": "12db31d9-b51c-4b59-9f3a-0310ab886bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#a= 0.3\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a=0.3\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  Y.append(np.cos(x))\n",
        "Ypred = model.predict(np.array(X))\n",
        "error = model.SE(Ypred,Y)\n",
        "print(Ypred)\n",
        "for err in error:\n",
        "  err+=err\n",
        "MSE = err/50\n",
        "print(MSE)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw22_a03.csv\", table, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.68488834 1.65876113 1.63263392 1.60650671 1.58037949 1.55425228\n",
            " 1.52674064 1.50108641 1.47169838 1.44256605 1.41457904 1.38368745\n",
            " 1.35619809 1.32843538 1.30033041 1.27362549 1.24409268 1.20637587\n",
            " 1.16785419 1.12137728 1.06337102 1.01986412 1.01870734 1.01231671\n",
            " 1.09038512 1.16580296 1.23503242 1.25858369 1.25362777 1.24702276\n",
            " 1.2763486  1.30254736 1.32972427 1.35544086 1.38395685 1.42139915\n",
            " 1.45926704 1.49407993 1.53175485 1.57171    1.6147902  1.65737611\n",
            " 1.6975593  1.73833952 1.77909548 1.81952476 1.86131666 1.90220387\n",
            " 1.94231908 1.98243429]\n",
            "0.3030867048994487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3JRbGOuRHRW",
        "outputId": "4fff2543-8153-403f-c3f0-b0f3f1d65d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#a= 1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a=1\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  Y.append(np.cos(x))\n",
        "Ypred = model.predict(np.array(X))\n",
        "error = model.SE(Ypred,Y)\n",
        "print(Ypred)\n",
        "for err in error:\n",
        "  err+=err\n",
        "MSE = err/50\n",
        "print(MSE)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw22_a1.csv\", table, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2786.61689772 2684.87241117 2583.12792462 2481.38343807 2379.63895152\n",
            " 2277.89446497 2176.10512381 2074.31083068 1972.46556649 1870.35307677\n",
            " 1767.87764934 1665.39995637 1562.92226341 1460.19542093 1357.43944034\n",
            " 1255.19772773 1153.98658863 1056.32628583  959.07208022  858.58249203\n",
            "  756.35553536  656.2126391   572.68194013  482.50792232  347.49085646\n",
            "  169.42754435  103.50641604  135.4183372   161.02673548  164.65336061\n",
            "  171.92419912  181.91329451  190.18220183  200.23123659  210.10656678\n",
            "  219.67871908  230.72569054  243.36949876  256.60916484  269.95815541\n",
            "  283.67804909  297.39794278  311.11783646  324.83773014  338.55762383\n",
            "  351.98073851  365.37635846  378.77197841  392.16759836  405.56321832]\n",
            "6604.274889569317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqlAV7ClSt70"
      },
      "source": [
        "Binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6D27u-BRM1m"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FFSN:\n",
        "  \n",
        "  def __init__(self, n_inputs, n_outputs,a, hidden_sizes=[100,100,100,100,100]):\n",
        "    self.nx = n_inputs\n",
        "    self.ny = n_outputs\n",
        "    self.nh = len(hidden_sizes)\n",
        "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
        "  \n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.nh+1):\n",
        "      self.W[i+1] = np.random.uniform(-a,a,(self.sizes[i], self.sizes[i+1]))\n",
        "      self.B[i+1] = np.full((1, self.sizes[i+1]),0.1)\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def relu(self,x):\n",
        "    return np.maximum(0,x)\n",
        "  def SE(self,yHat,y):\n",
        "    return np.square(np.subtract(yHat,y))\n",
        " \n",
        "\n",
        "  def forward_pass(self, x):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = x.reshape(1, -1)\n",
        "   \n",
        "    for i in range(self.nh):\n",
        "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
        "      self.H[i+1] = self.relu(self.A[i+1])\n",
        "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
        "    self.H[self.nh+1] = self.sigmoid(self.A[self.nh+1]) \n",
        "    return self.H[self.nh+1]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred).squeeze()\n",
        "  def cross_entropy(self,label,pred):\n",
        "    yl=np.multiply(pred,label)\n",
        "    yl=yl[yl!=0]\n",
        "    yl=-np.log(yl)\n",
        "    yl=np.mean(yl)\n",
        "    return yl\n",
        "  \n",
        "  def BinaryCrossEntropy(self,yHat, y):\n",
        "    if y == 1:\n",
        "      print(\"loss\",-np.log(yHat))\n",
        "      return -np.log(yHat)\n",
        "    else:\n",
        "      print(\"loss\",-np.log(1 - yHat))\n",
        "      return -np.log(1 - yHat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcqDplM2S2YJ",
        "outputId": "537915b6-4f7d-4cf8-d480-5ddf7e33639e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 0.1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.1\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y<0):\n",
        "    y=0\n",
        "  else:\n",
        "    y=1\n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.BinaryCrossEntropy(yHat,y))\n",
        "print(error)\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw23_a01.csv\", table, delimiter=\",\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat 0.5081795278527096\n",
            "y 0\n",
            "loss 0.7096415230894197\n",
            "yHat 0.5081524605867231\n",
            "y 0\n",
            "loss 0.7095864897536293\n",
            "yHat 0.5081257787913326\n",
            "y 0\n",
            "loss 0.7095322431231995\n",
            "yHat 0.5081018063264482\n",
            "y 0\n",
            "loss 0.7094835073291754\n",
            "yHat 0.5080783194861828\n",
            "y 0\n",
            "loss 0.7094357611087826\n",
            "yHat 0.5080560746743269\n",
            "y 0\n",
            "loss 0.7093905419005337\n",
            "yHat 0.5080386195523506\n",
            "y 0\n",
            "loss 0.7093550605958275\n",
            "yHat 0.5080006385724669\n",
            "y 0\n",
            "loss 0.7092778604021893\n",
            "yHat 0.5079504264033695\n",
            "y 0\n",
            "loss 0.7091758082229657\n",
            "yHat 0.5078886770137809\n",
            "y 0\n",
            "loss 0.7090503218520195\n",
            "yHat 0.507829365791758\n",
            "y 0\n",
            "loss 0.7089298051206883\n",
            "yHat 0.507764923266704\n",
            "y 0\n",
            "loss 0.7087988783606547\n",
            "yHat 0.5077253126929887\n",
            "y 0\n",
            "loss 0.7087184107509195\n",
            "yHat 0.5077155743575608\n",
            "y 0\n",
            "loss 0.7086986286265144\n",
            "yHat 0.5077678409799001\n",
            "y 0\n",
            "loss 0.7088048058574574\n",
            "yHat 0.5078446536199456\n",
            "y 0\n",
            "loss 0.7089608676517812\n",
            "yHat 0.5079307167921694\n",
            "y 0\n",
            "loss 0.709135752875857\n",
            "yHat 0.5080269059512635\n",
            "y 0\n",
            "loss 0.7093312508780236\n",
            "yHat 0.5081258394466623\n",
            "y 0\n",
            "loss 0.7095323664379228\n",
            "yHat 0.508227493427119\n",
            "y 0\n",
            "loss 0.7097390544372134\n",
            "yHat 0.5083006138969006\n",
            "y 0\n",
            "loss 0.709887753084243\n",
            "yHat 0.5083596147743459\n",
            "y 0\n",
            "loss 0.7100077540833613\n",
            "yHat 0.508427853931535\n",
            "y 0\n",
            "loss 0.7101465626422979\n",
            "yHat 0.5084946433964118\n",
            "y 0\n",
            "loss 0.7102824409729444\n",
            "yHat 0.5085556549680583\n",
            "y 0\n",
            "loss 0.7104065807363998\n",
            "yHat 0.5086201535649773\n",
            "y 1\n",
            "loss 0.676053801209042\n",
            "yHat 0.5086900754196645\n",
            "y 1\n",
            "loss 0.6759163370357639\n",
            "yHat 0.5087670045629151\n",
            "y 1\n",
            "loss 0.6757651185816184\n",
            "yHat 0.5088429194904232\n",
            "y 1\n",
            "loss 0.6756159161694671\n",
            "yHat 0.5089176140787063\n",
            "y 1\n",
            "loss 0.6754691339236372\n",
            "yHat 0.5089922666460048\n",
            "y 1\n",
            "loss 0.6753224557768855\n",
            "yHat 0.5090799597780706\n",
            "y 1\n",
            "loss 0.6751501828673481\n",
            "yHat 0.5091728537954737\n",
            "y 1\n",
            "loss 0.6749677251978529\n",
            "yHat 0.5092642529208741\n",
            "y 1\n",
            "loss 0.6747882362042902\n",
            "yHat 0.5093448587369835\n",
            "y 1\n",
            "loss 0.6746299697694915\n",
            "yHat 0.5094185753293248\n",
            "y 1\n",
            "loss 0.6744852519871195\n",
            "yHat 0.509526570525923\n",
            "y 1\n",
            "loss 0.6742732774810495\n",
            "yHat 0.5096156771337331\n",
            "y 1\n",
            "loss 0.6740984115911468\n",
            "yHat 0.5097031812904971\n",
            "y 1\n",
            "loss 0.6739267201596468\n",
            "yHat 0.509793915410253\n",
            "y 1\n",
            "loss 0.6737487223599687\n",
            "yHat 0.5098971983831199\n",
            "y 1\n",
            "loss 0.6735461453798951\n",
            "yHat 0.5100030651820942\n",
            "y 1\n",
            "loss 0.6733385431208576\n",
            "yHat 0.5101101436291409\n",
            "y 1\n",
            "loss 0.6731286086811992\n",
            "yHat 0.5101855930655154\n",
            "y 1\n",
            "loss 0.6729807114906131\n",
            "yHat 0.5102494835944157\n",
            "y 1\n",
            "loss 0.6728554893565545\n",
            "yHat 0.5103124283274464\n",
            "y 1\n",
            "loss 0.6727321362657225\n",
            "yHat 0.5103707039985891\n",
            "y 1\n",
            "loss 0.6726179467207788\n",
            "yHat 0.5104319058790809\n",
            "y 1\n",
            "loss 0.672498037386745\n",
            "yHat 0.5104805739233844\n",
            "y 1\n",
            "loss 0.6724026951408557\n",
            "yHat 0.5105292774907222\n",
            "y 1\n",
            "loss 0.6723072924034439\n",
            "[0.7096415230894197, 0.7095864897536293, 0.7095322431231995, 0.7094835073291754, 0.7094357611087826, 0.7093905419005337, 0.7093550605958275, 0.7092778604021893, 0.7091758082229657, 0.7090503218520195, 0.7089298051206883, 0.7087988783606547, 0.7087184107509195, 0.7086986286265144, 0.7088048058574574, 0.7089608676517812, 0.709135752875857, 0.7093312508780236, 0.7095323664379228, 0.7097390544372134, 0.709887753084243, 0.7100077540833613, 0.7101465626422979, 0.7102824409729444, 0.7104065807363998, 0.676053801209042, 0.6759163370357639, 0.6757651185816184, 0.6756159161694671, 0.6754691339236372, 0.6753224557768855, 0.6751501828673481, 0.6749677251978529, 0.6747882362042902, 0.6746299697694915, 0.6744852519871195, 0.6742732774810495, 0.6740984115911468, 0.6739267201596468, 0.6737487223599687, 0.6735461453798951, 0.6733385431208576, 0.6731286086811992, 0.6729807114906131, 0.6728554893565545, 0.6727321362657225, 0.6726179467207788, 0.672498037386745, 0.6724026951408557, 0.6723072924034439]\n",
            "totalerror 0.026892291696137757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-nV9cXNUOw-",
        "outputId": "52738eef-50a1-4c12-acef-9ed53d4fe688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 0.2\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.2\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y<0):\n",
        "    y=0\n",
        "  else:\n",
        "    y=1\n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.BinaryCrossEntropy(yHat,y))\n",
        "print(error)\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw23_a02.csv\", table, delimiter=\",\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat 0.7525155131138884\n",
            "y 0\n",
            "loss 1.3964073781858521\n",
            "yHat 0.749915940071089\n",
            "y 0\n",
            "loss 1.3859581779201515\n",
            "yHat 0.7472019550113129\n",
            "y 0\n",
            "loss 1.3751643501701643\n",
            "yHat 0.7444709677264008\n",
            "y 0\n",
            "loss 1.3644192465428147\n",
            "yHat 0.7418362901082216\n",
            "y 0\n",
            "loss 1.3541613608281342\n",
            "yHat 0.7391839642026043\n",
            "y 0\n",
            "loss 1.3439399638666802\n",
            "yHat 0.7365257093474299\n",
            "y 0\n",
            "loss 1.3337994844418017\n",
            "yHat 0.7339032055662899\n",
            "y 0\n",
            "loss 1.3238951475433935\n",
            "yHat 0.7312618667194057\n",
            "y 0\n",
            "loss 1.3140178557501336\n",
            "yHat 0.7284644771602211\n",
            "y 0\n",
            "loss 1.3036623089779746\n",
            "yHat 0.7257169523663997\n",
            "y 0\n",
            "loss 1.2935946852320492\n",
            "yHat 0.7228736932455245\n",
            "y 0\n",
            "loss 1.2832818956594836\n",
            "yHat 0.7202176058007067\n",
            "y 0\n",
            "loss 1.2737431415350062\n",
            "yHat 0.7176039275862222\n",
            "y 0\n",
            "loss 1.2644446813429884\n",
            "yHat 0.7147775865628031\n",
            "y 0\n",
            "loss 1.2544860050404396\n",
            "yHat 0.7117967100145781\n",
            "y 0\n",
            "loss 1.2440891798489033\n",
            "yHat 0.7083718388750713\n",
            "y 0\n",
            "loss 1.232275709008152\n",
            "yHat 0.7034794134594405\n",
            "y 0\n",
            "loss 1.2156386311146374\n",
            "yHat 0.6981834963406548\n",
            "y 0\n",
            "loss 1.1979360500502512\n",
            "yHat 0.691924515974011\n",
            "y 0\n",
            "loss 1.1774104480288134\n",
            "yHat 0.6852865005153639\n",
            "y 0\n",
            "loss 1.1560925794713406\n",
            "yHat 0.6782663235276579\n",
            "y 0\n",
            "loss 1.1340311673675867\n",
            "yHat 0.6719041644065458\n",
            "y 0\n",
            "loss 1.1144495315873895\n",
            "yHat 0.667391517033353\n",
            "y 0\n",
            "loss 1.1007892075375918\n",
            "yHat 0.6646447037322861\n",
            "y 0\n",
            "loss 1.0925647233071478\n",
            "yHat 0.6611515829180303\n",
            "y 1\n",
            "loss 0.4137721417932121\n",
            "yHat 0.6581120923607101\n",
            "y 1\n",
            "loss 0.41838000903348865\n",
            "yHat 0.6560373472211171\n",
            "y 1\n",
            "loss 0.42153755991909025\n",
            "yHat 0.6525867656353501\n",
            "y 1\n",
            "loss 0.4268111744717744\n",
            "yHat 0.6482995999689126\n",
            "y 1\n",
            "loss 0.4334023438476329\n",
            "yHat 0.6448258104505167\n",
            "y 1\n",
            "loss 0.4387750599765172\n",
            "yHat 0.6435010370515041\n",
            "y 1\n",
            "loss 0.44083164036760536\n",
            "yHat 0.6436363051384678\n",
            "y 1\n",
            "loss 0.4406214559793076\n",
            "yHat 0.6445417313494352\n",
            "y 1\n",
            "loss 0.4392157087387493\n",
            "yHat 0.6455284188745678\n",
            "y 1\n",
            "loss 0.4376860435227064\n",
            "yHat 0.645840946537427\n",
            "y 1\n",
            "loss 0.43720201830524114\n",
            "yHat 0.6462329056886161\n",
            "y 1\n",
            "loss 0.43659530505500815\n",
            "yHat 0.6466869504281016\n",
            "y 1\n",
            "loss 0.43589294944340146\n",
            "yHat 0.6471075174883452\n",
            "y 1\n",
            "loss 0.43524281978913854\n",
            "yHat 0.6474361791240987\n",
            "y 1\n",
            "loss 0.43473505532560597\n",
            "yHat 0.6477916981210673\n",
            "y 1\n",
            "loss 0.43418608782399043\n",
            "yHat 0.6484495926009224\n",
            "y 1\n",
            "loss 0.4331710074665684\n",
            "yHat 0.6494309531792977\n",
            "y 1\n",
            "loss 0.43165875617566324\n",
            "yHat 0.6503547056726112\n",
            "y 1\n",
            "loss 0.43023736389833156\n",
            "yHat 0.6513899721399945\n",
            "y 1\n",
            "loss 0.4286467805784325\n",
            "yHat 0.6523192397711016\n",
            "y 1\n",
            "loss 0.4272212053351289\n",
            "yHat 0.6532740199168218\n",
            "y 1\n",
            "loss 0.42575860538856714\n",
            "yHat 0.6542590467453757\n",
            "y 1\n",
            "loss 0.42425191000928547\n",
            "yHat 0.6552552749824275\n",
            "y 1\n",
            "loss 0.422730386475386\n",
            "yHat 0.656130251694281\n",
            "y 1\n",
            "loss 0.42139595533535273\n",
            "[1.3964073781858521, 1.3859581779201515, 1.3751643501701643, 1.3644192465428147, 1.3541613608281342, 1.3439399638666802, 1.3337994844418017, 1.3238951475433935, 1.3140178557501336, 1.3036623089779746, 1.2935946852320492, 1.2832818956594836, 1.2737431415350062, 1.2644446813429884, 1.2544860050404396, 1.2440891798489033, 1.232275709008152, 1.2156386311146374, 1.1979360500502512, 1.1774104480288134, 1.1560925794713406, 1.1340311673675867, 1.1144495315873895, 1.1007892075375918, 1.0925647233071478, 0.4137721417932121, 0.41838000903348865, 0.42153755991909025, 0.4268111744717744, 0.4334023438476329, 0.4387750599765172, 0.44083164036760536, 0.4406214559793076, 0.4392157087387493, 0.4376860435227064, 0.43720201830524114, 0.43659530505500815, 0.43589294944340146, 0.43524281978913854, 0.43473505532560597, 0.43418608782399043, 0.4331710074665684, 0.43165875617566324, 0.43023736389833156, 0.4286467805784325, 0.4272212053351289, 0.42575860538856714, 0.42425191000928547, 0.422730386475386, 0.42139595533535273]\n",
            "totalerror 0.01685583821341411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXbOb_OVE2A",
        "outputId": "632e0f0f-70a7-42bd-dd85-90aa3c4f0572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 0.3\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.3\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y<0):\n",
        "    y=0\n",
        "  else:\n",
        "    y=1\n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.BinaryCrossEntropy(yHat,y))\n",
        "print(error)\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw23_a03.csv\", table, delimiter=\",\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat 0.9941475755071066\n",
            "y 0\n",
            "loss 5.140899260366612\n",
            "yHat 0.9934206818413595\n",
            "y 0\n",
            "loss 5.023824162321085\n",
            "yHat 0.9925926825363205\n",
            "y 0\n",
            "loss 4.905286920915415\n",
            "yHat 0.9916558220750178\n",
            "y 0\n",
            "loss 4.786191237807488\n",
            "yHat 0.9906184191053808\n",
            "y 0\n",
            "loss 4.669006991293106\n",
            "yHat 0.9894299923657905\n",
            "y 0\n",
            "loss 4.549734756847702\n",
            "yHat 0.9880922696970411\n",
            "y 0\n",
            "loss 4.430567484476177\n",
            "yHat 0.9865729037526797\n",
            "y 0\n",
            "loss 4.310480505724787\n",
            "yHat 0.9849064856540578\n",
            "y 0\n",
            "loss 4.19349014094237\n",
            "yHat 0.983029781253113\n",
            "y 0\n",
            "loss 4.076295309607708\n",
            "yHat 0.9809164237577012\n",
            "y 0\n",
            "loss 3.958927196442821\n",
            "yHat 0.9785987047608308\n",
            "y 0\n",
            "loss 3.8443038335910833\n",
            "yHat 0.9760074030217697\n",
            "y 0\n",
            "loss 3.7300099554579322\n",
            "yHat 0.973124726178993\n",
            "y 0\n",
            "loss 3.6165486038975834\n",
            "yHat 0.9699405635452091\n",
            "y 0\n",
            "loss 3.504578642178654\n",
            "yHat 0.9661534853346931\n",
            "y 0\n",
            "loss 3.385919249022306\n",
            "yHat 0.9620962111689717\n",
            "y 0\n",
            "loss 3.27270420273392\n",
            "yHat 0.958163578055871\n",
            "y 0\n",
            "loss 3.1739879804700473\n",
            "yHat 0.9530859782091792\n",
            "y 0\n",
            "loss 3.0594386761274195\n",
            "yHat 0.9482894348481791\n",
            "y 0\n",
            "loss 2.962093163377863\n",
            "yHat 0.9446496113447125\n",
            "y 0\n",
            "loss 2.894071598076398\n",
            "yHat 0.9457692888547768\n",
            "y 0\n",
            "loss 2.9145079047129703\n",
            "yHat 0.9491938857074941\n",
            "y 0\n",
            "loss 2.979738571551696\n",
            "yHat 0.949121357391459\n",
            "y 0\n",
            "loss 2.978312038597396\n",
            "yHat 0.9491407919509747\n",
            "y 0\n",
            "loss 2.9786940903043364\n",
            "yHat 0.9500896433018013\n",
            "y 1\n",
            "loss 0.051198937468987384\n",
            "yHat 0.9502278210787586\n",
            "y 1\n",
            "loss 0.05105351147591964\n",
            "yHat 0.9469553839701006\n",
            "y 1\n",
            "loss 0.05450329992586912\n",
            "yHat 0.9427335805286259\n",
            "y 1\n",
            "loss 0.058971559565347796\n",
            "yHat 0.9435562535257439\n",
            "y 1\n",
            "loss 0.05809929377201474\n",
            "yHat 0.9454290152155495\n",
            "y 1\n",
            "loss 0.05611647015303446\n",
            "yHat 0.9481963033147683\n",
            "y 1\n",
            "loss 0.05319372715621748\n",
            "yHat 0.9510623361144988\n",
            "y 1\n",
            "loss 0.050175670620148105\n",
            "yHat 0.9536990665581521\n",
            "y 1\n",
            "loss 0.04740710115610933\n",
            "yHat 0.9564569230367304\n",
            "y 1\n",
            "loss 0.04451952714658274\n",
            "yHat 0.9597903860408833\n",
            "y 1\n",
            "loss 0.041040366235702626\n",
            "yHat 0.9632781857105837\n",
            "y 1\n",
            "loss 0.03741303484963609\n",
            "yHat 0.9665561770368734\n",
            "y 1\n",
            "loss 0.03401585782540793\n",
            "yHat 0.9694336932475702\n",
            "y 1\n",
            "loss 0.031043199369036635\n",
            "yHat 0.9720496571546314\n",
            "y 1\n",
            "loss 0.028348388218979857\n",
            "yHat 0.9746685655234989\n",
            "y 1\n",
            "loss 0.025657798570951205\n",
            "yHat 0.9770974477263742\n",
            "y 1\n",
            "loss 0.023168890125749287\n",
            "yHat 0.9793554200718406\n",
            "y 1\n",
            "loss 0.02086065834040119\n",
            "yHat 0.9814154982285466\n",
            "y 1\n",
            "loss 0.01875936349204204\n",
            "yHat 0.9832701120908105\n",
            "y 1\n",
            "loss 0.016871413172257457\n",
            "yHat 0.985000450577272\n",
            "y 1\n",
            "loss 0.015113180371297937\n",
            "yHat 0.9866191578736985\n",
            "y 1\n",
            "loss 0.01347117229511183\n",
            "yHat 0.9880664878511976\n",
            "y 1\n",
            "loss 0.012005288102553876\n",
            "yHat 0.9893631516675326\n",
            "y 1\n",
            "loss 0.010693823991497946\n",
            "yHat 0.9905080755319632\n",
            "y 1\n",
            "loss 0.009537259891443077\n",
            "[5.140899260366612, 5.023824162321085, 4.905286920915415, 4.786191237807488, 4.669006991293106, 4.549734756847702, 4.430567484476177, 4.310480505724787, 4.19349014094237, 4.076295309607708, 3.958927196442821, 3.8443038335910833, 3.7300099554579322, 3.6165486038975834, 3.504578642178654, 3.385919249022306, 3.27270420273392, 3.1739879804700473, 3.0594386761274195, 2.962093163377863, 2.894071598076398, 2.9145079047129703, 2.979738571551696, 2.978312038597396, 2.9786940903043364, 0.051198937468987384, 0.05105351147591964, 0.05450329992586912, 0.058971559565347796, 0.05809929377201474, 0.05611647015303446, 0.05319372715621748, 0.050175670620148105, 0.04740710115610933, 0.04451952714658274, 0.041040366235702626, 0.03741303484963609, 0.03401585782540793, 0.031043199369036635, 0.028348388218979857, 0.025657798570951205, 0.023168890125749287, 0.02086065834040119, 0.01875936349204204, 0.016871413172257457, 0.015113180371297937, 0.01347117229511183, 0.012005288102553876, 0.010693823991497946, 0.009537259891443077]\n",
            "totalerror 0.00038149039565772306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVMXSNqMVKi_",
        "outputId": "98636240-1978-4186-facc-8d8f1b8d91a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 1\n",
        "model = FFSN(1,1,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y<0):\n",
        "    y=0\n",
        "  else:\n",
        "    y=1\n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.BinaryCrossEntropy(yHat,y))\n",
        "print(error)\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "table = np.array([X,Y,Ypred,error])\n",
        "np.savetxt(\"hw23_a1.csv\", table, delimiter=\",\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat 1.5140172125297684e-09\n",
            "y 0\n",
            "loss 1.5140172460540855e-09\n",
            "yHat 1.257488627340087e-09\n",
            "y 0\n",
            "loss 1.2574886695395018e-09\n",
            "yHat 9.951267422692594e-10\n",
            "y 0\n",
            "loss 9.951267592689176e-10\n",
            "yHat 7.827184489344973e-10\n",
            "y 0\n",
            "loss 7.827184459196082e-10\n",
            "yHat 6.15648383518491e-10\n",
            "y 0\n",
            "loss 6.156484213212208e-10\n",
            "yHat 7.567993774205562e-10\n",
            "y 0\n",
            "loss 7.567994012113627e-10\n",
            "yHat 1.456169524202444e-09\n",
            "y 0\n",
            "loss 1.4561695193592922e-09\n",
            "yHat 2.6285867690405604e-09\n",
            "y 0\n",
            "loss 2.6285867961292597e-09\n",
            "yHat 3.547894106601538e-09\n",
            "y 0\n",
            "loss 3.547894095922077e-09\n",
            "yHat 3.2626234899876528e-09\n",
            "y 0\n",
            "loss 3.2626235100185497e-09\n",
            "yHat 4.285138932433297e-09\n",
            "y 0\n",
            "loss 4.285138919557171e-09\n",
            "yHat 4.808802021462127e-09\n",
            "y 0\n",
            "loss 4.8088020348106925e-09\n",
            "yHat 5.077371648527988e-09\n",
            "y 0\n",
            "loss 5.0773716471332285e-09\n",
            "yHat 5.200702100044429e-09\n",
            "y 0\n",
            "loss 5.200702104725143e-09\n",
            "yHat 3.582696777956826e-08\n",
            "y 0\n",
            "loss 3.5826968367646296e-08\n",
            "yHat 6.414169786049952e-06\n",
            "y 0\n",
            "loss 6.414190356959209e-06\n",
            "yHat 0.00549963588782526\n",
            "y 0\n",
            "loss 0.005514814562310123\n",
            "yHat 0.5411089950530322\n",
            "y 0\n",
            "loss 0.7789425591093312\n",
            "yHat 0.9910567673409729\n",
            "y 0\n",
            "loss 4.716858160186948\n",
            "yHat 0.9998529032037516\n",
            "y 0\n",
            "loss 8.824419710006985\n",
            "yHat 0.9999992973607826\n",
            "y 0\n",
            "loss 14.168422281187654\n",
            "yHat 1.0\n",
            "y 0\n",
            "loss inf\n",
            "yHat 1.0\n",
            "y 0\n",
            "loss inf\n",
            "yHat 1.0\n",
            "y 0\n",
            "loss inf\n",
            "yHat 1.0\n",
            "y 0\n",
            "loss inf\n",
            "yHat 1.8851800354936713e-05\n",
            "y 1\n",
            "loss 10.878902139085286\n",
            "yHat 1.251841819251523e-39\n",
            "y 1\n",
            "loss 89.57620270452261\n",
            "yHat 3.1752036351858946e-42\n",
            "y 1\n",
            "loss 95.55320213839553\n",
            "yHat 7.578426776002044e-47\n",
            "y 1\n",
            "loss 106.19619374194731\n",
            "yHat 3.430053036646802e-50\n",
            "y 1\n",
            "loss 113.89667892606474\n",
            "yHat 3.4208966078398936e-59\n",
            "y 1\n",
            "loss 134.62261780389863\n",
            "yHat 1.6273639597392843e-66\n",
            "y 1\n",
            "loss 151.483654634486\n",
            "yHat 1.2347931448690567e-73\n",
            "y 1\n",
            "loss 167.87780832654724\n",
            "yHat 3.3593171316595235e-80\n",
            "y 1\n",
            "loss 182.99506972082864\n",
            "yHat 1.9916839873472194e-87\n",
            "y 1\n",
            "loss 199.63592258479432\n",
            "yHat 1.28493454593053e-95\n",
            "y 1\n",
            "loss 218.49487605440353\n",
            "yHat 3.3247393420021906e-103\n",
            "y 1\n",
            "loss 235.9648733007346\n",
            "yHat 9.470413566197539e-111\n",
            "y 1\n",
            "loss 253.33877274490166\n",
            "yHat 1.806777059716179e-118\n",
            "y 1\n",
            "loss 271.11349634521673\n",
            "yHat 3.446991327992547e-126\n",
            "y 1\n",
            "loss 288.8882199455312\n",
            "yHat 4.755461792178687e-134\n",
            "y 1\n",
            "loss 306.9871086527429\n",
            "yHat 1.460965999377307e-142\n",
            "y 1\n",
            "loss 326.5879853448146\n",
            "yHat 3.6604274338974454e-151\n",
            "y 1\n",
            "loss 346.3927691162886\n",
            "yHat 9.171143616318327e-160\n",
            "y 1\n",
            "loss 366.1975528877612\n",
            "yHat 2.2978156718024113e-168\n",
            "y 1\n",
            "loss 386.00233665923486\n",
            "yHat 3.8786633051214817e-177\n",
            "y 1\n",
            "loss 406.20207087465707\n",
            "yHat 5.3783161038249145e-186\n",
            "y 1\n",
            "loss 426.5984519635651\n",
            "yHat 7.457797142238259e-195\n",
            "y 1\n",
            "loss 446.9948330524739\n",
            "yHat 1.034129217046096e-203\n",
            "y 1\n",
            "loss 467.3912141413832\n",
            "yHat 1.4339666487995013e-212\n",
            "y 1\n",
            "loss 487.7875952302927\n",
            "[1.5140172460540855e-09, 1.2574886695395018e-09, 9.951267592689176e-10, 7.827184459196082e-10, 6.156484213212208e-10, 7.567994012113627e-10, 1.4561695193592922e-09, 2.6285867961292597e-09, 3.547894095922077e-09, 3.2626235100185497e-09, 4.285138919557171e-09, 4.8088020348106925e-09, 5.0773716471332285e-09, 5.200702104725143e-09, 3.5826968367646296e-08, 6.414190356959209e-06, 0.005514814562310123, 0.7789425591093312, 4.716858160186948, 8.824419710006985, 14.168422281187654, inf, inf, inf, inf, 10.878902139085286, 89.57620270452261, 95.55320213839553, 106.19619374194731, 113.89667892606474, 134.62261780389863, 151.483654634486, 167.87780832654724, 182.99506972082864, 199.63592258479432, 218.49487605440353, 235.9648733007346, 253.33877274490166, 271.11349634521673, 288.8882199455312, 306.9871086527429, 326.5879853448146, 346.3927691162886, 366.1975528877612, 386.00233665923486, 406.20207087465707, 426.5984519635651, 446.9948330524739, 467.3912141413832, 487.7875952302927]\n",
            "totalerror 19.511503809211707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDB2IjxpXmTw"
      },
      "source": [
        "Multiclass Classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNovOzgqXqLH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FFSN:\n",
        "  \n",
        "  def __init__(self, n_inputs, n_outputs,a, hidden_sizes=[100,100,100,100,100]):\n",
        "    self.nx = n_inputs\n",
        "    self.ny = n_outputs\n",
        "    self.nh = len(hidden_sizes)\n",
        "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
        "  \n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.nh+1):\n",
        "      self.W[i+1] = np.random.uniform(-a,a,(self.sizes[i], self.sizes[i+1]))\n",
        "      self.B[i+1] = np.full((1, self.sizes[i+1]),0.1)\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "  \n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def relu(self,x):\n",
        "    return np.maximum(0,x)\n",
        "  def SE(self,yHat,y):\n",
        "    return np.square(np.subtract(yHat,y))\n",
        " \n",
        "\n",
        "  def forward_pass(self, x):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = x.reshape(1, -1)\n",
        "   \n",
        "    for i in range(self.nh):\n",
        "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
        "      self.H[i+1] = self.relu(self.A[i+1])\n",
        "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
        "    self.H[self.nh+1] = self.softmax(self.A[self.nh+1]) \n",
        "    return self.H[self.nh+1]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = []\n",
        "    for x in X:\n",
        "      y_pred = self.forward_pass(x)\n",
        "      Y_pred.append(y_pred)\n",
        "    return np.array(Y_pred).squeeze()\n",
        "  def crossentropy(self,yHat,Y):\n",
        "    loss=0\n",
        "    for yhat,y in zip(yHat,Y):\n",
        "      loss+=-y*np.log(yhat)\n",
        "    print(\"loss\",loss)\n",
        "    return loss\n",
        " \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwnyZ2rQb0mT",
        "outputId": "3dc11399-ffde-452b-df2e-adc558639128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 0.1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.1\n",
        "model = FFSN(1,6,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y==-3):\n",
        "    y=[1,0,0,0,0,0]\n",
        "  elif (y==-2):\n",
        "    y= [0,1,0,0,0,0]\n",
        "  elif(y==-1):\n",
        "    y= [0,0,1,0,0,0]\n",
        "  elif(y==0):\n",
        "    y= [0,0,0,1,0,0]\n",
        "  elif(y== 1):\n",
        "    y= [0,0,0,0,1,0]\n",
        "  elif(y == 2):\n",
        "    y= [0,0,0,0,0,1]\n",
        "         \n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "error_my = []\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.crossentropy(yHat,y))\n",
        "print(error)\n",
        "\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat [0.16237556 0.15928998 0.16377254 0.16038127 0.17933301 0.17484764]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8092767718395872\n",
            "yHat [0.16238565 0.15923044 0.16379409 0.16041197 0.17929918 0.17487867]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.809145182648784\n",
            "yHat [0.16239536 0.15917303 0.16381198 0.160439   0.17926862 0.17491201]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8090359771626845\n",
            "yHat [0.16240219 0.15911814 0.16382321 0.16047135 0.17923231 0.17495279]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.808967430265883\n",
            "yHat [0.16240561 0.15906741 0.16382734 0.16050873 0.17919452 0.1749964 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8089422395775117\n",
            "yHat [0.16241052 0.15901382 0.16382822 0.16055107 0.17915998 0.1750364 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.808936833063976\n",
            "yHat [0.16241576 0.15896073 0.16382626 0.16058931 0.17912764 0.1750803 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8089488062183683\n",
            "yHat [0.16241449 0.1589173  0.16381852 0.16061804 0.17909913 0.17513252]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8089960662952742\n",
            "yHat [0.16240861 0.15886804 0.16380256 0.1606493  0.17907106 0.17520044]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8090934739371338\n",
            "yHat [0.16240085 0.15881887 0.16378678 0.16067986 0.17903847 0.17527518]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8091898186909774\n",
            "yHat [0.16239679 0.15876798 0.16376704 0.16071079 0.17900897 0.17534843]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8093103623215299\n",
            "yHat [0.16239969 0.15872658 0.1637473  0.16073208 0.17898424 0.17541011]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8094308651099218\n",
            "yHat [0.16239623 0.15868657 0.16375135 0.16074767 0.17895141 0.17546677]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8094061489048001\n",
            "yHat [0.16237933 0.15865915 0.16373544 0.16075674 0.17892656 0.17554278]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8095033156249425\n",
            "yHat [0.16235761 0.15865366 0.16370369 0.16075815 0.17891615 0.17561074]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8096972585296485\n",
            "yHat [0.16232242 0.15864836 0.16370274 0.1607665  0.17889095 0.17566903]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8097030483068173\n",
            "yHat [0.16227794 0.15863434 0.16370363 0.1607734  0.17887547 0.17573523]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.809697594830898\n",
            "yHat [0.16222858 0.1586176  0.16370293 0.16078135 0.17886676 0.17580279]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.809701914870567\n",
            "yHat [0.16217923 0.15860086 0.16370221 0.16078928 0.17885805 0.17587036]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8097062784772378\n",
            "yHat [0.16212959 0.15858427 0.16370126 0.16079742 0.17884924 0.17593823]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8097120961227893\n",
            "yHat [0.16207109 0.15857057 0.16369204 0.16081354 0.17883636 0.17601639]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8097684003474286\n",
            "yHat [0.16201706 0.15855232 0.1636841  0.16083203 0.17882103 0.17609347]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8098169067321577\n",
            "yHat [0.16197278 0.15852426 0.16368335 0.16085219 0.17880155 0.17616588]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8098215267907576\n",
            "yHat [0.1619292  0.15849493 0.163684   0.16087216 0.17877811 0.17624159]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8098175090364972\n",
            "yHat [0.16189073 0.15846333 0.16368821 0.16088995 0.17874422 0.17632355]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 1.8097918124223795\n",
            "yHat [0.1618569  0.15843786 0.16369311 0.16089285 0.17872522 0.17639405]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7219057347933877\n",
            "yHat [0.16184189 0.1584107  0.16369652 0.16089713 0.17869582 0.17645794]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7220702329616475\n",
            "yHat [0.16183636 0.15837904 0.16369616 0.16090512 0.17866272 0.17652059]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7222554766104614\n",
            "yHat [0.16183509 0.15834274 0.16369534 0.16091885 0.17862558 0.17658241]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.72246341370529\n",
            "yHat [0.16183385 0.15830638 0.16369451 0.16093263 0.1785884  0.17664423]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7226715573929\n",
            "yHat [0.16183599 0.15826763 0.16368839 0.1609469  0.17854738 0.17671371]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7229012543445748\n",
            "yHat [0.16184391 0.1582258  0.16367857 0.16096102 0.1785045  0.17678619]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7231414873105317\n",
            "yHat [0.16185966 0.15818104 0.16367033 0.16097379 0.17846487 0.1768503 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.723363483335357\n",
            "yHat [0.1618735  0.15813216 0.16366495 0.16098885 0.17842253 0.17691801]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.723600754125136\n",
            "yHat [0.16188116 0.15808077 0.16365733 0.16100312 0.17838283 0.17699479]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7238232895053922\n",
            "yHat [0.16189224 0.1580292  0.16365393 0.16101679 0.17834305 0.1770648 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.724046363146751\n",
            "yHat [0.16190961 0.15798471 0.1636561  0.16102384 0.17831295 0.17711279]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.724215142701459\n",
            "yHat [0.16194545 0.15793509 0.16363889 0.1610417  0.17828271 0.17715615]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.724384718531318\n",
            "yHat [0.16198425 0.15790705 0.16361875 0.16106212 0.17824075 0.17718709]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7246201394377552\n",
            "yHat [0.16202494 0.15788779 0.16359069 0.1610804  0.17819644 0.17721973]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.724868745706127\n",
            "yHat [0.16206817 0.15786793 0.16357728 0.16109156 0.17814878 0.17724628]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7251362336564262\n",
            "yHat [0.16211315 0.15784346 0.16357442 0.16109858 0.17810194 0.17726844]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7253991778035267\n",
            "yHat [0.16215485 0.15782378 0.1635832  0.16110083 0.17805459 0.17728276]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7256650950823922\n",
            "yHat [0.16218414 0.15781037 0.16360314 0.16110015 0.17799845 0.17730376]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7259804531578855\n",
            "yHat [0.16220947 0.15780263 0.16362514 0.16110852 0.17794519 0.17730905]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7262797242840255\n",
            "yHat [0.16223555 0.15779434 0.16364384 0.16111507 0.1779017  0.1773095 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.72652414952928\n",
            "yHat [0.16226323 0.15778782 0.16365365 0.16111281 0.17786777 0.17731472]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.72671486874111\n",
            "yHat [0.16229381 0.1577818  0.1636545  0.16110624 0.17783741 0.17732624]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7268855599734723\n",
            "yHat [0.16232864 0.15777952 0.16365092 0.16110051 0.17780809 0.17733234]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7270504829446196\n",
            "yHat [0.16236085 0.15778038 0.16364275 0.16109719 0.17777913 0.1773397 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 1.7272133599185124\n",
            "[1.8092767718395872, 1.809145182648784, 1.8090359771626845, 1.808967430265883, 1.8089422395775117, 1.808936833063976, 1.8089488062183683, 1.8089960662952742, 1.8090934739371338, 1.8091898186909774, 1.8093103623215299, 1.8094308651099218, 1.8094061489048001, 1.8095033156249425, 1.8096972585296485, 1.8097030483068173, 1.809697594830898, 1.809701914870567, 1.8097062784772378, 1.8097120961227893, 1.8097684003474286, 1.8098169067321577, 1.8098215267907576, 1.8098175090364972, 1.8097918124223795, 1.7219057347933877, 1.7220702329616475, 1.7222554766104614, 1.72246341370529, 1.7226715573929, 1.7229012543445748, 1.7231414873105317, 1.723363483335357, 1.723600754125136, 1.7238232895053922, 1.724046363146751, 1.724215142701459, 1.724384718531318, 1.7246201394377552, 1.724868745706127, 1.7251362336564262, 1.7253991778035267, 1.7256650950823922, 1.7259804531578855, 1.7262797242840255, 1.72652414952928, 1.72671486874111, 1.7268855599734723, 1.7270504829446196, 1.7272133599185124]\n",
            "totalerror 0.0690885343967405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlt61V3Mdze0",
        "outputId": "64fb3e9a-370d-4af6-bd3f-bbcfeee8c032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 0.2\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.2\n",
        "model = FFSN(1,6,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y==-3):\n",
        "    y=[1,0,0,0,0,0]\n",
        "  elif (y==-2):\n",
        "    y= [0,1,0,0,0,0]\n",
        "  elif(y==-1):\n",
        "    y= [0,0,1,0,0,0]\n",
        "  elif(y==0):\n",
        "    y= [0,0,0,1,0,0]\n",
        "  elif(y== 1):\n",
        "    y= [0,0,0,0,1,0]\n",
        "  elif(y == 2):\n",
        "    y= [0,0,0,0,0,1]\n",
        "         \n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "error_my = []\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.crossentropy(yHat,y))\n",
        "print(error)\n",
        "\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat [0.1974246  0.22219612 0.09609227 0.15173052 0.11804664 0.21450984]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.342446403354948\n",
            "yHat [0.19671319 0.22081674 0.09645353 0.152224   0.11832361 0.21546893]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.338693914020945\n",
            "yHat [0.1959878  0.21953266 0.09684043 0.15260771 0.1185663  0.21646509]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3346906740807913\n",
            "yHat [0.19529265 0.21823454 0.09715736 0.15299369 0.11878116 0.2175406 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3314233195349736\n",
            "yHat [0.19460481 0.21715227 0.0974659  0.15329907 0.11918341 0.21829455]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3282527455500155\n",
            "yHat [0.19393275 0.21613881 0.09778126 0.15360556 0.11959746 0.21894415]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3250223422529595\n",
            "yHat [0.19326961 0.21522672 0.09812088 0.15401371 0.1198694  0.21949968]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3215551319799284\n",
            "yHat [0.19253307 0.21415476 0.09849952 0.15459006 0.12015709 0.22006549]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.317703600576383\n",
            "yHat [0.19175351 0.21311968 0.09889514 0.15524487 0.12043612 0.22055068]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3136951586159427\n",
            "yHat [0.1910807  0.21205871 0.0992271  0.15590539 0.120694   0.2210341 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3103440667064143\n",
            "yHat [0.19033997 0.21104717 0.09952078 0.15661738 0.12094203 0.22153268]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.307388816653654\n",
            "yHat [0.18948676 0.21037646 0.09994965 0.15730897 0.1210706  0.22180756]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.3030887081292284\n",
            "yHat [0.18886376 0.20971379 0.10041651 0.15757988 0.12134899 0.22207708]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.298428681306569\n",
            "yHat [0.18840306 0.20906485 0.1008553  0.15773098 0.12163823 0.22230758]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2940684321070135\n",
            "yHat [0.18789565 0.20890907 0.10104504 0.15788237 0.1218909  0.22237697]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.292188944335103\n",
            "yHat [0.18734256 0.20953029 0.10099339 0.1579004  0.12211899 0.22211437]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2927002132285135\n",
            "yHat [0.18682565 0.21049662 0.10097332 0.15787743 0.12233962 0.22148736]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2928989094909187\n",
            "yHat [0.18634369 0.21246848 0.10090714 0.15768251 0.12243449 0.22016369]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.293554580394029\n",
            "yHat [0.18586862 0.21355902 0.1009577  0.15791911 0.12304036 0.21865518]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.29305363394631\n",
            "yHat [0.18514616 0.21393381 0.10111396 0.15876254 0.12397395 0.21706958]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2915070954007337\n",
            "yHat [0.18381709 0.21441614 0.10146928 0.15965138 0.12518241 0.2154637 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2879991574838385\n",
            "yHat [0.18245432 0.21490986 0.10196618 0.16126764 0.12618196 0.21322004]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2831140964329206\n",
            "yHat [0.18167416 0.21275632 0.10246811 0.16481842 0.12657253 0.21171046]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.2782036414449958\n",
            "yHat [0.18072301 0.20908746 0.10277189 0.16963031 0.12661852 0.21116881]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.275243414185916\n",
            "yHat [0.18030647 0.20462383 0.10331408 0.17412428 0.12749664 0.21013469]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.269981564936217\n",
            "yHat [0.17967881 0.20121097 0.10427385 0.17815195 0.12859467 0.20808976]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0510899412509356\n",
            "yHat [0.17919622 0.19861297 0.10488998 0.18176297 0.1298731  0.20566475]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0411974293610915\n",
            "yHat [0.17941513 0.19722321 0.1057406  0.18542466 0.13009537 0.20210103]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.039487484775212\n",
            "yHat [0.17870797 0.1949961  0.10649918 0.1901385  0.13081133 0.19884692]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.033999193299628\n",
            "yHat [0.17822505 0.1930952  0.10688949 0.19428661 0.13113197 0.19637167]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0315510438032467\n",
            "yHat [0.17756928 0.19123517 0.1071817  0.19869725 0.13127306 0.19404354]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.03047567885406\n",
            "yHat [0.17699701 0.18944981 0.10721016 0.20281927 0.13109463 0.19242911]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0318358339128464\n",
            "yHat [0.17655529 0.18841888 0.10666152 0.2055911  0.13093775 0.19183546]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0330332410559726\n",
            "yHat [0.17617163 0.18778378 0.10614167 0.2075104  0.13107653 0.19131599]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.031973953520185\n",
            "yHat [0.17645008 0.18717722 0.1057196  0.20887205 0.13152657 0.19025448]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.02854639707488\n",
            "yHat [0.17665408 0.186721   0.10531907 0.20974317 0.13194075 0.18962193]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0254022986062754\n",
            "yHat [0.17718405 0.18679518 0.10498248 0.21023913 0.13206191 0.18873725]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.024484429417107\n",
            "yHat [0.17783588 0.18703126 0.10454438 0.21063949 0.13210713 0.18784185]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0241420752682435\n",
            "yHat [0.17869794 0.18704248 0.1040117  0.21108202 0.13230896 0.1868569 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0226155143087694\n",
            "yHat [0.17946393 0.18685144 0.1034803  0.21170824 0.13249275 0.18600333]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0212273214875935\n",
            "yHat [0.18030621 0.18628884 0.10288302 0.21259046 0.13267863 0.18525284]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.019825354839855\n",
            "yHat [0.18091108 0.18600575 0.1023883  0.21335992 0.13297787 0.18435709]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0175725802936286\n",
            "yHat [0.18130298 0.18579382 0.10192765 0.21417993 0.13316583 0.18362979]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0161600910545605\n",
            "yHat [0.18180155 0.18556514 0.10146694 0.21501215 0.13315198 0.18300225]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0162640997536347\n",
            "yHat [0.18230081 0.18535893 0.10099061 0.21585267 0.13315746 0.18233952]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.01622294352992\n",
            "yHat [0.18283311 0.1850872  0.1004946  0.21677553 0.13320042 0.18160914]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.01590040427496\n",
            "yHat [0.18334756 0.1848439  0.09999153 0.21767601 0.1332465  0.1808945 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.0155544636928178\n",
            "yHat [0.18389952 0.18467542 0.09955735 0.21839041 0.13329072 0.18018657]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.01522265557921\n",
            "yHat [0.18440001 0.18469319 0.09913966 0.21900513 0.13331012 0.17945189]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.01507714069843\n",
            "yHat [0.18480985 0.18485498 0.09872783 0.21954607 0.13335835 0.17870292]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.014715417407096\n",
            "[2.342446403354948, 2.338693914020945, 2.3346906740807913, 2.3314233195349736, 2.3282527455500155, 2.3250223422529595, 2.3215551319799284, 2.317703600576383, 2.3136951586159427, 2.3103440667064143, 2.307388816653654, 2.3030887081292284, 2.298428681306569, 2.2940684321070135, 2.292188944335103, 2.2927002132285135, 2.2928989094909187, 2.293554580394029, 2.29305363394631, 2.2915070954007337, 2.2879991574838385, 2.2831140964329206, 2.2782036414449958, 2.275243414185916, 2.269981564936217, 2.0510899412509356, 2.0411974293610915, 2.039487484775212, 2.033999193299628, 2.0315510438032467, 2.03047567885406, 2.0318358339128464, 2.0330332410559726, 2.031973953520185, 2.02854639707488, 2.0254022986062754, 2.024484429417107, 2.0241420752682435, 2.0226155143087694, 2.0212273214875935, 2.019825354839855, 2.0175725802936286, 2.0161600910545605, 2.0162640997536347, 2.01622294352992, 2.01590040427496, 2.0155544636928178, 2.01522265557921, 2.01507714069843, 2.014715417407096]\n",
            "totalerror 0.08058861669628384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CCZvU9nhkGN",
        "outputId": "db1c620c-fd80-42fc-934f-341e8c06a594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#a= 1\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "labelledDataList = []\n",
        "\n",
        "\n",
        "a= 0.3\n",
        "model = FFSN(1,6,a,[100,100,100,100,100])\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1,51):\n",
        "  labelledData ={}\n",
        "  x=(i-25.5)/10\n",
        "  X.append(x)\n",
        "  y = np.sign(x)\n",
        "  if(y==-3):\n",
        "    y=[1,0,0,0,0,0]\n",
        "  elif (y==-2):\n",
        "    y= [0,1,0,0,0,0]\n",
        "  elif(y==-1):\n",
        "    y= [0,0,1,0,0,0]\n",
        "  elif(y==0):\n",
        "    y= [0,0,0,1,0,0]\n",
        "  elif(y== 1):\n",
        "    y= [0,0,0,0,1,0]\n",
        "  elif(y == 2):\n",
        "    y= [0,0,0,0,0,1]\n",
        "         \n",
        "  Y.append(y)\n",
        "Ypred = model.predict(np.array(X))\n",
        "#error = model.BinaryCrossEntropy(Ypred,Y)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Ypred)\n",
        "error =[]\n",
        "error_my = []\n",
        "for yHat,y in zip(Ypred,Y):\n",
        "  print(\"yHat\",yHat)\n",
        "  print(\"y\",y)\n",
        "  error.append(model.crossentropy(yHat,y))\n",
        "print(error)\n",
        "\n",
        "for err in error:\n",
        "  err+=err\n",
        "totalerror = err/50\n",
        "print(\"totalerror\",totalerror)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yHat [0.0621932  0.08844399 0.01635635 0.00457653 0.43883773 0.38959219]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 4.113139358639627\n",
            "yHat [0.06384178 0.09161933 0.01734826 0.00514653 0.43277958 0.38926451]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 4.054262894488633\n",
            "yHat [0.06540307 0.09468895 0.01836525 0.00576865 0.42610608 0.38966802]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.9972951545527104\n",
            "yHat [0.06685183 0.09806872 0.01951553 0.00646994 0.4166413  0.39245268]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.936544745398709\n",
            "yHat [0.06827857 0.10170079 0.02080392 0.00727344 0.40702433 0.39491895]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.8726137271298144\n",
            "yHat [0.06971559 0.10564057 0.02227601 0.00819324 0.39751713 0.39665746]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.804245163817814\n",
            "yHat [0.07133418 0.10957589 0.02386071 0.00922678 0.38881812 0.39718431]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.73552205800309\n",
            "yHat [0.07364736 0.11424195 0.02562519 0.01047831 0.37906105 0.39694614]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.664179275983813\n",
            "yHat [0.07594494 0.11882915 0.02759484 0.0119334  0.36879511 0.39690258]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.590126627788119\n",
            "yHat [0.07790436 0.12134719 0.02993138 0.01364031 0.35732077 0.39985599]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.5088477932739575\n",
            "yHat [0.08004827 0.12369469 0.03223764 0.01551522 0.34701062 0.40149356]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.434620506064042\n",
            "yHat [0.08243519 0.12535673 0.03502108 0.01758559 0.33461628 0.40498513]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.3518051933587136\n",
            "yHat [0.08379227 0.12498363 0.03821622 0.01990174 0.32434633 0.4087598 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.264495209635949\n",
            "yHat [0.08482538 0.12320331 0.04228983 0.02259334 0.31450892 0.41257922]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.1632086961505803\n",
            "yHat [0.08484843 0.11987036 0.04677616 0.02572475 0.30445148 0.41832882]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 3.0623816302891216\n",
            "yHat [0.08540959 0.11602541 0.05159135 0.02961397 0.29355766 0.42380202]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.9644012852776345\n",
            "yHat [0.08717755 0.11247594 0.05627453 0.03447457 0.28614838 0.42344903]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.877513203656368\n",
            "yHat [0.09080186 0.10851378 0.06038862 0.03996272 0.28428151 0.4160515 ]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.806954566102592\n",
            "yHat [0.09420585 0.10826734 0.06478092 0.04433753 0.27492706 0.41348131]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.7367441519196745\n",
            "yHat [0.0986635  0.10856867 0.06727423 0.04798667 0.26856315 0.40894379]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.6989780261913396\n",
            "yHat [0.10123296 0.10592226 0.07088324 0.05411251 0.25875586 0.40909316]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.6467212441784707\n",
            "yHat [0.10843275 0.09953625 0.07452662 0.06217455 0.23294497 0.42238486]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.596598892035416\n",
            "yHat [0.11331353 0.09683688 0.07471806 0.06326722 0.19633476 0.45552956]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.5940334932524536\n",
            "yHat [0.11560536 0.09392141 0.07053549 0.06209722 0.16748379 0.49035674]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.6516393379646765\n",
            "yHat [0.11626357 0.09645569 0.06815809 0.05902927 0.14007349 0.52001988]\n",
            "y [0, 0, 1, 0, 0, 0]\n",
            "loss 2.685925358086587\n",
            "yHat [0.11123145 0.09595226 0.06192442 0.0561435  0.11620222 0.55854615]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.1524233513605004\n",
            "yHat [0.10891282 0.10058381 0.05519792 0.05316436 0.09981748 0.58232361]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.304411958845699\n",
            "yHat [0.10333244 0.10442921 0.0451617  0.04761144 0.08932908 0.61013612]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.415428195321601\n",
            "yHat [0.09733542 0.10598206 0.03833267 0.04377946 0.08550965 0.62906074]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.4591260569395588\n",
            "yHat [0.09685252 0.11291926 0.03383856 0.0393822  0.08119042 0.63581704]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.5109579894380323\n",
            "yHat [0.08992513 0.11040177 0.02975877 0.034896   0.07313675 0.66188158]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.6154242912052568\n",
            "yHat [0.08298718 0.1071431  0.02569334 0.03072961 0.06459405 0.68885273]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.7396330497702768\n",
            "yHat [0.08051833 0.1045648  0.02234594 0.0273214  0.05757776 0.70767178]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.8546189653226173\n",
            "yHat [0.07731408 0.10212717 0.01947534 0.02366132 0.05009047 0.72733163]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 2.9939245761761084\n",
            "yHat [0.07342663 0.09943399 0.0169102  0.02027562 0.0432937  0.74665986]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.13974807676882\n",
            "yHat [0.06929907 0.0959023  0.01436474 0.01728289 0.03732603 0.76582498]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.28806437817967\n",
            "yHat [0.06541847 0.0928467  0.01246147 0.0151287  0.03391568 0.78022899]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.3838779181010215\n",
            "yHat [0.06052788 0.08960154 0.01081402 0.01330736 0.03110483 0.79464438]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.470392230883182\n",
            "yHat [0.05581687 0.08705584 0.00961884 0.01180664 0.02888244 0.80681938]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.5445216062628293\n",
            "yHat [0.05166872 0.08469818 0.00857704 0.01055529 0.02668317 0.8178176 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.6237222241662015\n",
            "yHat [0.04802167 0.08220035 0.00760489 0.00946067 0.02458497 0.82812745]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.705619961792208\n",
            "yHat [0.04453923 0.07894424 0.00669173 0.00839351 0.02244595 0.83898535]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.7966451039139915\n",
            "yHat [0.04133928 0.07570794 0.0058497  0.00742214 0.0204405  0.84924044]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.890237030971482\n",
            "yHat [0.03855208 0.07260138 0.00507795 0.00652878 0.01871217 0.85852764]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 3.9785812624526504\n",
            "yHat [0.0359078  0.0696232  0.00440348 0.00575117 0.01710116 0.86721319]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.0686090793361585\n",
            "yHat [0.03340401 0.06687129 0.00381988 0.0050855  0.01557525 0.87524407]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.1620718554114475\n",
            "yHat [0.03107126 0.06426749 0.00331622 0.00449926 0.01416062 0.88268516]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.257290715538621\n",
            "yHat [0.02888437 0.06172865 0.00287728 0.00397825 0.01286687 0.88966458]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.353099429159405\n",
            "yHat [0.02690126 0.05937864 0.00249804 0.0035229  0.01171436 0.89598481]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.446939495340787\n",
            "yHat [0.02503928 0.0570316  0.00216867 0.00312052 0.01068973 0.9019502 ]\n",
            "y [0, 0, 0, 0, 1, 0]\n",
            "loss 4.538472245677888\n",
            "[4.113139358639627, 4.054262894488633, 3.9972951545527104, 3.936544745398709, 3.8726137271298144, 3.804245163817814, 3.73552205800309, 3.664179275983813, 3.590126627788119, 3.5088477932739575, 3.434620506064042, 3.3518051933587136, 3.264495209635949, 3.1632086961505803, 3.0623816302891216, 2.9644012852776345, 2.877513203656368, 2.806954566102592, 2.7367441519196745, 2.6989780261913396, 2.6467212441784707, 2.596598892035416, 2.5940334932524536, 2.6516393379646765, 2.685925358086587, 2.1524233513605004, 2.304411958845699, 2.415428195321601, 2.4591260569395588, 2.5109579894380323, 2.6154242912052568, 2.7396330497702768, 2.8546189653226173, 2.9939245761761084, 3.13974807676882, 3.28806437817967, 3.3838779181010215, 3.470392230883182, 3.5445216062628293, 3.6237222241662015, 3.705619961792208, 3.7966451039139915, 3.890237030971482, 3.9785812624526504, 4.0686090793361585, 4.1620718554114475, 4.257290715538621, 4.353099429159405, 4.446939495340787, 4.538472245677888]\n",
            "totalerror 0.18153888982711552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk1MzuAfhtG4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}